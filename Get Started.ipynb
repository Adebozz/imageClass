{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Plotting library\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files   \n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot more samples of nevus compared to the other two. This might cause the network to be biased. It will try to maximize the error function, and by classifying everything as nevus it will accomplish that.\n",
    "\n",
    "For this problem we will need to be careful with the accuracy metric. I will try to balance the data in the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_train_path = '../input/skin-lesion-analysis-towards-melanoma-detection/train/train'\n",
    "data_valid_path = '../input/skin-lesion-analysis-towards-melanoma-detection/valid/valid'\n",
    "data_test_path = '../input/skin-lesion-analysis-towards-melanoma-detection/test/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA\n",
    "\n",
    "Lets find out how many samples we have for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_data_raw (path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    \n",
    "    return files, targets\n",
    "\n",
    "train_filenames, train_targets = load_data_raw(data_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_trimmed = [filename.split('/')[-2] for filename in train_filenames]\n",
    "classes_count = Counter(filenames_trimmed)\n",
    "\n",
    "# Plot the classes\n",
    "plt.bar(classes_count.keys(), classes_count.values(), color=['blue', 'orange', 'green'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling function for imbalanced data\n",
    "\n",
    "Using scikit learn's resample function I will create new samples of the under-represented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_samples(filenames):\n",
    "    filenames_trimmed = [filename.split('/')[-2] for filename in filenames]\n",
    "    classes_count = Counter(filenames_trimmed)\n",
    "\n",
    "    # Plot the classes\n",
    "    plt.bar(classes_count.keys(), classes_count.values(), color=['blue', 'orange', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "# Choose one of the 3 for the feature_name\n",
    "feature_names = {0: 'melanoma', 1: 'nevus', 2: 'seborrheic_keratosis'}\n",
    "\n",
    "def upsample(filenames, targets, feature_name, n_samples = 1372):\n",
    "    upsample_idx = []\n",
    "    \n",
    "\n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If feature matches, save the index\n",
    "        if feature_name in path.split('/'):\n",
    "            upsample_idx.append(i)\n",
    "    \n",
    "    # Remove selected features from filenames to add the upsampled after\n",
    "    new_filenames = [filename for i, filename in enumerate(filenames) if i not in upsample_idx]\n",
    "    new_targets = [target for i, target in enumerate(targets) if i not in upsample_idx]\n",
    "\n",
    "    # Upsample\n",
    "    resampled_x, resampled_y = resample(filenames[upsample_idx], targets[upsample_idx], n_samples=n_samples, random_state=0)\n",
    "\n",
    "    # Add the upsampled features to new_filenames and new_targets\n",
    "    new_filenames += list(resampled_x)\n",
    "    new_targets += list(resampled_y) \n",
    "    \n",
    "    return np.array(new_filenames), np.array(new_targets)\n",
    "    \n",
    "# We upsample twice: once for each feature we want upsampled\n",
    "upsample_train_x, upsample_train_y = upsample(train_filenames, train_targets, feature_names[0])\n",
    "upsample_train_x, upsample_train_y = upsample(upsample_train_x, upsample_train_y, feature_names[2])\n",
    "\n",
    "plot_n_samples(upsample_train_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling function for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Use only if not using the up-sampling function\n",
    "def downsample(filenames, targets, n_samples = 370):\n",
    "    nevus_idx = []\n",
    "    \n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If nevus, save the index\n",
    "        if 'nevus' in path.split('/'):\n",
    "            nevus_idx.append(i)\n",
    "    \n",
    "    nevus_idx = np.sort(shuffle(nevus_idx)[n_samples:]) # shuffle indices\n",
    "\n",
    "    # Downsample\n",
    "    new_filenames = [filename for i, filename in enumerate(filenames) if i not in nevus_idx]\n",
    "    new_targets = [target for i, target in enumerate(targets) if i not in nevus_idx]\n",
    "    \n",
    "    \n",
    "    return new_filenames, new_targets\n",
    "            \n",
    "downsample_train_x, downsample_train_y = downsample(train_filenames, train_targets)\n",
    "\n",
    "plot_n_samples(downsample_train_x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image   \n",
    "\n",
    "# Convert the image paths to tensors Manually\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "train_filenames = paths_to_tensor(upsample_train_x)\n",
    "train_targets = upsample_train_y"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
