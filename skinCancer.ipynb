{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define some variables to store the dataset path, image size, and number of classes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image file\n",
    "image = Image.open(\"./data/happy/0.jpg\")\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"./skin-lesion-analysis-towards-melanoma-detection/Test/actinic keratosis/\"\n",
    "IMG_SIZE = 100\n",
    "NUM_CLASSES = 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DATADIR variable should be replaced with the path to the dataset directory on your machine. The IMG_SIZE variable defines the size of the images after resizing. The NUM_CLASSES variable defines the number of classes in the dataset.\n",
    "\n",
    "Now, let's define a function to preprocess the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resize the image to IMG_SIZE x IMG_SIZE\n",
    "    resized = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "    # Normalize the image to have pixel values between 0 and 1\n",
    "    normalized = resized / 255.0\n",
    "    # Reshape the image to have a single color channel\n",
    "    reshaped = np.reshape(normalized, (IMG_SIZE, IMG_SIZE, 1))\n",
    "    return reshaped\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes an image as input, converts it to grayscale, resizes it to IMG_SIZE x IMG_SIZE, normalizes it to have pixel values between 0 and 1, and reshapes it to have a single color channel.\n",
    "\n",
    "Now, let's load the images and labels from the dataset directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './skin-lesion-analysis-towards-melanoma-detection/Test/actinic keratosis/0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATADIR, \u001b[39mstr\u001b[39m(label))\n\u001b[0;32m      7\u001b[0m \u001b[39m# Loop over each image file in the label directory\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m img_filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(path):\n\u001b[0;32m      9\u001b[0m     img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, img_filename)\n\u001b[0;32m     10\u001b[0m     \u001b[39m# Load the image data and preprocess it\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './skin-lesion-analysis-towards-melanoma-detection/Test/actinic keratosis/0'"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop over each label\n",
    "for label in range(NUM_CLASSES):\n",
    "    path = os.path.join(DATADIR, str(label))\n",
    "    # Loop over each image file in the label directory\n",
    "    for img_filename in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_filename)\n",
    "        # Load the image data and preprocess it\n",
    "        img_data = cv2.imread(img_path)\n",
    "        img_data = preprocess_image(img_data)\n",
    "        # Append the image data and label to the arrays\n",
    "        images.append(img_data)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert the images and labels to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Shuffle the images and labels\n",
    "np.random.seed(1)  # Set the random seed for reproducibility\n",
    "idx = np.random.permutation(len(images))\n",
    "images, labels = images[idx], labels[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loops over each class in the dataset directory, loads each image, preprocesses it using the preprocess_image() function, and appends it to the images list along with its label. Finally, it converts the images and labels lists to NumPy arrays and shuffles them.\n",
    "\n",
    "Now, let's split the dataset into training and testing sets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the train_test_split() function from the sklearn library to split the images and labels arrays into training and testing sets, with 20% of the data used for testing.\n",
    "\n",
    "Next, let's define the CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a sequential model with the following layers:\n",
    "\n",
    "1. `Conv2D` layer with 32 filters, kernel size of 3x3, ReLU activation function, and input shape of `IMG_SIZE x IMG_SIZE x 1`.\n",
    "2. `MaxPooling2D` layer with pool size of 2x2.\n",
    "3. `Conv2D` layer with 64 filters, kernel size of 3x3, ReLU activation function.\n",
    "4. `MaxPooling2D` layer with pool size of 2x2.\n",
    "5. `Conv2D` layer with 128 filters, kernel size of 3x3, ReLU activation function.\n",
    "6. `MaxPooling2D` layer with pool size of 2x2.\n",
    "7. `Flatten` layer to convert the output of the convolutional layers to a 1D array.\n",
    "8. `Dense` layer with 128 neurons and ReLU activation function.\n",
    "9. `Dense` layer with `NUM_CLASSES` neurons and softmax activation function.\n",
    "\n",
    "Finally, let's compile and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code compiles the model using the Adam optimizer, sparse categorical crossentropy loss function, and accuracy metric. It then trains the model for 10 epochs on the training data, with validation on the testing data.\n",
    "\n",
    "That's it! This program should be able to classify skin cancer images and non-cancer images using a CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
