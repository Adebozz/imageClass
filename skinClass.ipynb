{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Importing necessary libraries\n",
    "First, we need to import the necessary libraries for our program. We'll be using TensorFlow and Keras for building and training our model, NumPy for data manipulation, and Matplotlib for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Loading the dataset\n",
    "Next, we need to load the dataset. We'll be using the \"Skin Cancer MNIST: HAM10000\" dataset, which contains 10,015 images of skin lesions, classified into 7 categories. You can download the dataset from Kaggle or from the following link: https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to the directory where the dataset is stored\n",
    "# dataset_path = './skin-lesion-analysis-towards-melanoma-detection/'\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "data_dir = './skin-lesion-analysis-towards-melanoma-detection/' # path to the directory containing the dataset\n",
    "categories = os.listdir(data_dir) # list of categories in the dataset\n",
    "\n",
    "data = []\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        try:\n",
    "            # read image using cv2\n",
    "            img_array = cv2.imread(img_path)\n",
    "            # convert image to grayscale\n",
    "            gray_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "            # resize image to (100, 100)\n",
    "            resized_img = cv2.resize(gray_img, (100, 100))\n",
    "            # add image and corresponding label to data list\n",
    "            data.append([resized_img, category])\n",
    "        except Exception as e:\n",
    "            # skip images that cannot be read by cv2\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Preprocessing the data\n",
    "Before training our model, we need to preprocess the data. In this case, we'll simply normalize the pixel values to be between 0 and 1, and reshape the images to be of size (28, 28, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape images\n",
    "x_train = x_train.reshape(-1, 28, 28, 3)\n",
    "x_test = x_test.reshape(-1, 28, 28, 3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Defining the model architecture\n",
    "Now we're ready to define our CNN architecture. We'll use the following layers:\n",
    "\n",
    "1. Conv2D layer with 32 filters, kernel size of (3, 3), ReLU activation, and padding='same'\n",
    "2. MaxPooling2D layer with pool size of (2, 2)\n",
    "3. Conv2D layer with 64 filters, kernel size of (3, 3), ReLU activation, and padding='same'\n",
    "4. MaxPooling2D layer with pool size of (2, 2)\n",
    "5. Conv2D layer with 128 filters, kernel size of (3, 3), ReLU activation, and padding='same'\n",
    "6. MaxPooling2D layer with pool size of (2, 2)\n",
    "7. Flatten layer\n",
    "8. Dense layer with 128 units and ReLU activation\n",
    "9. Dropout layer with rate of 0.5\n",
    "10. Dense layer with 7 units and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(7)\n",
    "    (activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Compiling the model\n",
    "\n",
    "Next, we need to compile our model. We'll use categorical cross-entropy as the loss function, Adam as the optimizer, and accuracy as the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Training the model\n",
    "Now we're ready to train our model. We'll use a batch size of 32, and train for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Evaluating the model\n",
    "After training, we can evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Visualizing the results\n",
    "Finally, we can visualize the training and validation accuracy and loss over the epochs using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
